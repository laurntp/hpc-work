{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7257c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_path = \"/rds/user/hpcpin1/hpc-work/Datasets/Cytomine/Droso/Train\"\n",
    "test_path = \"/rds/user/hpcpin1/hpc-work/Datasets/Cytomine/Droso/Test\"\n",
    "val_path = \"/rds/user/hpcpin1/hpc-work/Datasets/Cytomine/Droso/Val\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026c39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02278c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.hybrid import Hybrid as Hybrid\n",
    "from models.hybridSkip import Hybrid as Skip\n",
    "from models.hybridDoubleSkip import Hybrid as DoubleSkip\n",
    "\n",
    "import os \n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataLoader import LandmarksDataset, ToTensor, Rescale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.sparse as sp\n",
    "from utils.utils import scipy_to_torch_sparse, genMatrixesLH, genMatrixesOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7084379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(test_path, 'Images')\n",
    "label_path = os.path.join(test_path, 'landmarks')\n",
    "test_dataset = LandmarksDataset(img_path=img_path,\n",
    "                                 label_path=label_path,\n",
    "                                 transform = transforms.Compose([\n",
    "                                             Rescale(1024),\n",
    "                                             ToTensor()])\n",
    "                                 )\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab56929b-895f-45ca-954a-553ff76e5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from models.hybridNoPool import Hybrid as HybridNoPool\n",
    "\n",
    "#A, AD, D, U = genMatrixesLH()\n",
    "A, AD, D, U = genMatrixesOne(15)\n",
    "\n",
    "\n",
    "A = sp.csc_matrix(A).tocoo()\n",
    "AD = sp.csc_matrix(AD).tocoo()\n",
    "D = sp.csc_matrix(D).tocoo()\n",
    "U = sp.csc_matrix(U).tocoo()\n",
    "\n",
    "D_ = [D.copy()]\n",
    "U_ = [U.copy()]\n",
    "\n",
    "config = {}\n",
    "config['n_nodes'] = [120, 120, 120, 120, 120, 120]\n",
    "\n",
    "A_ = [A.copy(), A.copy(), A.copy(), A.copy(), A.copy(), A.copy()]\n",
    "\n",
    "A_t, D_t, U_t = ([scipy_to_torch_sparse(x).to(device) for x in X] for X in (A_, D_, U_))\n",
    "\n",
    "config['latents'] = 64\n",
    "config['inputsize'] = 1024\n",
    "\n",
    "f = 32\n",
    "config['filters'] = [2, f, f, f, f//2, f//2, f//2]\n",
    "config['skip_features'] = f\n",
    "config['K'] = 6\n",
    "\n",
    "hybridNP = HybridNoPool(config.copy(), D_t, U_t, A_t).to(device)\n",
    "hybridNP.load_state_dict(torch.load(\"../weights/hybrid_no_pool/bestMSE_2000.pt\"))\n",
    "hybridNP.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb6ec1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Hybrid:\n\tsize mismatch for dec_lin.weight: copying a param with shape torch.Size([960, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for dec_lin.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     37\u001b[0m double54 \u001b[38;5;241m=\u001b[39m DoubleSkip(config\u001b[38;5;241m.\u001b[39mcopy(), D_t, U_t, A_t)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mdouble54\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../weights/Skip/double_L54/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m double54\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loaded\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Hybrid:\n\tsize mismatch for dec_lin.weight: copying a param with shape torch.Size([960, 64]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for dec_lin.bias: copying a param with shape torch.Size([960]) from checkpoint, the shape in current model is torch.Size([128])."
     ]
    }
   ],
   "source": [
    "#A, AD, D, U = genMatrixesLH()\n",
    "A, AD, D, U = genMatrixesOne(15)\n",
    "\n",
    "\n",
    "A = sp.csc_matrix(A).tocoo()\n",
    "AD = sp.csc_matrix(AD).tocoo()\n",
    "D = sp.csc_matrix(D).tocoo()\n",
    "U = sp.csc_matrix(U).tocoo()\n",
    "\n",
    "D_ = [D.copy()]\n",
    "U_ = [U.copy()]\n",
    "A_ = [A.copy(), A.copy(), A.copy(), AD.copy(), AD.copy(), AD.copy()]\n",
    "\n",
    "#config = {}\n",
    "#config['n_nodes'] = [120, 120, 120, 60, 60, 60]\n",
    "N1 = A.shape[0]\n",
    "N2 = AD.shape[0]\n",
    "\n",
    "config = {}\n",
    "config['n_nodes'] = config['n_nodes'] = [N1, N1, N1, N2, N2, N2]\n",
    "\n",
    "A_t, D_t, U_t = ([scipy_to_torch_sparse(x).to(device) for x in X] for X in (A_, D_, U_))\n",
    "\n",
    "config['latents'] = 64\n",
    "config['inputsize'] = 1024\n",
    "\n",
    "f = 32\n",
    "config['filters'] = [2, f, f, f, f//2, f//2, f//2]\n",
    "config['skip_features'] = f\n",
    "\n",
    "config['window'] = (3,3)\n",
    "\n",
    "config['K'] = 6\n",
    "config['l1'] = 5\n",
    "config['l2'] = 4\n",
    "\n",
    "double54 = DoubleSkip(config.copy(), D_t, U_t, A_t).to(device)\n",
    "double54.load_state_dict(torch.load(\"../weights/Skip/double_L54/best.pt\"))\n",
    "double54.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['l1'] = 6\n",
    "config['l2'] = 5\n",
    "\n",
    "double65 = DoubleSkip(config.copy(), D_t, U_t, A_t).to(device)\n",
    "double65.load_state_dict(torch.load(\"/rds/user/hpcpin1/hpc-work/Training/hybrid_droso24081803/bestMSE.pt\"))\n",
    "double65.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3a5f6-a5e4-4d90-817e-871f10b1a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['l1'] = 4\n",
    "config['l2'] = 3\n",
    "\n",
    "double43 = DoubleSkip(config.copy(), D_t, U_t, A_t).to(device)\n",
    "double43.load_state_dict(torch.load(\"../weights/Skip/double_L43/best.pt\"))\n",
    "double43.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f06511",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = Hybrid(config, D_t, U_t, A_t).to(device)\n",
    "hybrid.load_state_dict(torch.load(\"../weights/HybridGNet/best.pt\"))\n",
    "hybrid.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['layer'] = 3\n",
    "\n",
    "Skip3 = Skip(config, D_t, U_t, A_t).to(device)\n",
    "Skip3.load_state_dict(torch.load(\"../weights/Skip/skip_L3/best.pt\"))\n",
    "Skip3.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['layer'] = 4\n",
    "\n",
    "Skip4 = Skip(config, D_t, U_t, A_t).to(device)\n",
    "Skip4.load_state_dict(torch.load(\"../weights/Skip/skip_L4/best.pt\"))\n",
    "Skip4.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b54181",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['layer'] = 5\n",
    "\n",
    "Skip5 = Skip(config, D_t, U_t, A_t).to(device)\n",
    "Skip5.load_state_dict(torch.load(\"../weights/Skip/skip_L5/best.pt\"))\n",
    "Skip5.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['layer'] = 6\n",
    "\n",
    "Skip6 = Skip(config, D_t, U_t, A_t).to(device)\n",
    "Skip6.load_state_dict(torch.load(\"../weights/Skip/skip_L6/best.pt\"))\n",
    "Skip6.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b5eed-0c89-4f77-b1d4-8699aa326395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pca import PCA_Net\n",
    "\n",
    "config['extended'] = False\n",
    "config['device'] = device\n",
    "\n",
    "pcaNet = PCA_Net(config.copy()).to(device)\n",
    "pcaNet.load_state_dict(torch.load('../weights/baselines/pca/best.pt'))\n",
    "pcaNet.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58521387-5a2c-43d3-b664-22e338b54e5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/rds/user/hpcpin1/hpc-work/Training/vae_droso24082131/bestMSE.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallOrgans\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      5\u001b[0m vae \u001b[38;5;241m=\u001b[39m VAE_Mixed(config\u001b[38;5;241m.\u001b[39mcopy())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m vae\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/rds/user/hpcpin1/hpc-work/Training/vae_droso24082131/bestMSE.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m vae\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loaded\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/torch2/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/rds/user/hpcpin1/hpc-work/Training/vae_droso24082131/bestMSE.pt'"
     ]
    }
   ],
   "source": [
    "from models.vae_Droso import VAE_Mixed\n",
    "\n",
    "config['allOrgans'] = False\n",
    "\n",
    "vae = VAE_Mixed(config.copy()).to(device)\n",
    "vae.load_state_dict(torch.load('/rds/user/hpcpin1/hpc-work/Training/vae_droso24082131/bestMSE.pt'))\n",
    "vae.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import UNet\n",
    "\n",
    "modelUNet = UNet(n_classes = 2).to(device)\n",
    "modelUNet.load_state_dict(torch.load('/rds/user/hpcpin1/hpc-work/Training/unet_droso24081804/bestDice_2500.pt'))\n",
    "modelUNet.eval()\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "model_list = [pcaNet, vae, hybrid, Skip3, Skip4, Skip5, Skip6, double43, double54, double65]\n",
    "model_names = ['PCA', 'FC', 'HybridGNet', '1-SC Layer 3', '1-SC Layer 4','1-SC Layer 5','1-SC Layer 6', '2-SC Layers 4-3', '2-SC Layers 5-4', '2-SC Layers 6-5']\n",
    "\n",
    "results1 = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(test_dataset.images)):   \n",
    "    print('\\r',i+1,'of', len(test_dataset.images),end='')\n",
    "    with torch.no_grad():\n",
    "        sample = test_dataset[i]\n",
    "\n",
    "        data, target = sample['image'], sample['landmarks']\n",
    "        data = torch.unsqueeze(data, 0).to(device)\n",
    "        target =  target[:120,:].reshape(-1).numpy()\n",
    "        \n",
    "        for j in range(0, len(model_list)):\n",
    "            output = model_list[j](data)\n",
    "            if len(output) > 1:\n",
    "                output = output[0]\n",
    "            output = output.cpu().numpy().reshape(-1)\n",
    "            \n",
    "            error = mean_squared_error(target * 1024, output * 1024)\n",
    "            \n",
    "            aux = pd.DataFrame([[i, error, model_names[j]]], columns=['i','MSE', 'Model'])\n",
    "            results1 = pd.concat([results1, aux], ignore_index=True) #results1.append(aux, ignore_index = True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e5ade-d3e7-44e2-9963-7c4f5faaf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#model_list = [pcaNet, vae, hybrid, Skip3, Skip4, Skip5, Skip6, double43, double54, double65]\n",
    "#model_names = ['PCA', 'FC', 'HybridGNet', '1-SC Layer 3', '1-SC Layer 4','1-SC Layer 5','1-SC Layer 6', '2-SC Layers 4-3', '2-SC Layers 5-4', '2-SC Layers 6-5']\n",
    "model_list = [vae, double65]\n",
    "model_names = ['FC', '2-SC Layers 6-5']\n",
    "\n",
    "results1 = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(test_dataset.images)):   \n",
    "    print('\\r',i+1,'of', len(test_dataset.images),end='')\n",
    "    with torch.no_grad():\n",
    "        sample = test_dataset[i]\n",
    "\n",
    "        data, target = sample['image'], sample['landmarks']\n",
    "        data = torch.unsqueeze(data, 0).to(device)\n",
    "        target =  target[:120,:].reshape(-1).numpy()\n",
    "\n",
    "        for j in range(0, len(model_list)):\n",
    "            output = model_list[j](data)\n",
    "            if len(output) > 1:\n",
    "                output = output[0]\n",
    "            output = output.cpu().numpy().reshape(-1)\n",
    "            \n",
    "            error = mean_squared_error(target * 1024, output * 1024)\n",
    "            \n",
    "            aux = pd.DataFrame([[i, error, model_names[j]]], columns=['i','MSE', 'Model'])\n",
    "            results1 = pd.concat([results1, aux], ignore_index=True) #results1.append(aux, ignore_index = True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbf3a3-760e-4c97-82a4-323235bd5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "def natural_key(string_):\n",
    "    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
    "\n",
    "folder = \"MultiAtlas/JSRT/images/output_points\"\n",
    "test = \"../Datasets/JSRT/Test/landmarks\"\n",
    "\n",
    "data_root = pathlib.Path(folder)\n",
    "all_files = list(data_root.glob('*.npy'))\n",
    "all_files = [str(path) for path in all_files]\n",
    "all_files.sort(key = natural_key)\n",
    "\n",
    "for i in range(0, len(all_files)):\n",
    "    data = np.load(all_files[i])[:240]\n",
    "    target = np.load(all_files[i].replace(folder, test))[:240]\n",
    "    \n",
    "    error = mean_squared_error(target, data)\n",
    "\n",
    "    aux = pd.DataFrame([[i, error, \"MultiAtlas\"]], columns=['i','MSE', 'Model'])\n",
    "    results1 = pd.concat([results1, aux], ignore_index=True) #results1 = results1.append(aux, ignore_index = True)\n",
    "    \n",
    "model_names.append('MultiAtlas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.tight_layout()\n",
    "sns.boxplot(x = 'Model', y = 'MSE', data = results1, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE')\n",
    "plt.xlabel(None)\n",
    "\n",
    "print('MSE')\n",
    "for model in model_names:\n",
    "    print(model, '\\t' '%.3f'%np.mean(results1['MSE'][results1['Model'] == model]), '+- %.3f' % np.std(results1['MSE'][results1['Model'] == model]))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names.append('UNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = results1[results1['Model'] == '2-SC Layers 6-5']\n",
    "aux0 = aux.sort_values(by = 'MSE')[-3:]\n",
    "aux0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a3d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.fun import drawOrgans\n",
    "\n",
    "#model_list_ = [pcaNet, vae, hybrid, Skip6, double65]\n",
    "#model_names_ = ['PCA', 'FC', 'HybridGNet', '1-IGSC Layer 6', '2-IGSC Layers 6-5']\n",
    "model_list_ = [vae, double65]\n",
    "model_names_ = ['FC', '2-IGSC Layers 6-5']\n",
    "\n",
    "i_ =[5, 10, 15]\n",
    "\n",
    "fig = plt.figure(figsize=(24, 8), dpi= 200)\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in i_:\n",
    "    with torch.no_grad():\n",
    "        sample = test_dataset[i]\n",
    "\n",
    "        data, target = sample['image'], sample['landmarks']\n",
    "        data = torch.unsqueeze(data, 0).to(device)\n",
    "        target = target.reshape(-1).numpy()\n",
    "\n",
    "        draw = data.cpu().numpy()[0,0,:,:]\n",
    "        \n",
    "        ax = plt.subplot(3, len(model_list_) + 3, 1 + c * (len(model_list_) + 3))\n",
    "        plt.axis('off')\n",
    "        plt.xlim(1, 1024)\n",
    "        plt.ylim(1024, 1)\n",
    "        \n",
    "        target = np.clip(target, 0, 1)\n",
    "        if c == 0:\n",
    "            drawOrgans(ax, target[:240] * 1024, None, draw.copy())\n",
    "            plt.title(\"Ground Truth\", fontsize = 20)\n",
    "        else:\n",
    "            drawOrgans(ax, target[:240] * 1024, None, draw.copy())\n",
    "        \n",
    "        ax = plt.subplot(3, len(model_list_) + 3, 2 + c * (len(model_list_) + 3))\n",
    "        \n",
    "        #data_MA = test_dataset.images[i].replace('Datasets/JSRT/Test/Images', \"Results/MultiAtlas/JSRT/images/output_points\").replace(\".png\", \".npy\")\n",
    "        #data_MA = np.load(data_MA)[:240]\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.xlim(1, 1024)\n",
    "        plt.ylim(1024, 1)\n",
    "        #drawOrgans(ax, data_MA, None, draw.copy())\n",
    "        #if c == 0:\n",
    "            #plt.title(\"MultiAtlas\", fontsize = 20)\n",
    "        \n",
    "        for j in range(0, len(model_list_)):\n",
    "            output = model_list_[j](data)\n",
    "            if len(output) > 1:\n",
    "                output = output[0]\n",
    "            output = output.cpu().numpy().reshape(-1) \n",
    "            output = np.clip(output, 0, 1)[:240]\n",
    "            ax = plt.subplot(3, len(model_list_) + 3, j + 3 + c * (len(model_list_) + 3))\n",
    "            plt.axis('off')\n",
    "            if c == 0:\n",
    "                drawOrgans(ax, output * 1024, None, draw.copy())\n",
    "                plt.title(model_names_[j], fontsize = 20)\n",
    "            else:\n",
    "                drawOrgans(ax, output * 1024, None, draw.copy())\n",
    "            \n",
    "            plt.xlim(1, 1024)\n",
    "            plt.ylim(1024, 1)\n",
    "\n",
    "        \n",
    "        ax = plt.subplot(3, len(model_list_) + 3, j + 4 + c * (len(model_list_) + 3))\n",
    "        plt.axis('off')\n",
    "\n",
    "        output = modelUNet(data)\n",
    "        output = torch.argmax(output[0,:,:,:], axis=0).cpu().numpy()\n",
    "        \n",
    "        image=np.zeros(list(draw.shape) + [3])\n",
    "        image[:,:,0] = draw + 0.7 * (output == 1).astype('float') - 0.3 * (output == 2).astype('float')\n",
    "        image[:,:,1] = draw + 0.7 * (output == 2).astype('float') - 0.2 * (output == 1).astype('float')\n",
    "        image[:,:,2] = draw - 0.2 * (output == 1).astype('float') - 0.3 * (output == 2).astype('float')\n",
    "        image = np.clip(image, 0, 1)\n",
    "        if c == 0:\n",
    "            plt.title('UNet', fontsize = 20)\n",
    "        plt.imshow(image)\n",
    "        plt.xlim(1, 1024)\n",
    "        plt.ylim(1024, 1)\n",
    "        \n",
    "        c += 1\n",
    "        \n",
    "fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.01, hspace=0)      \n",
    "plt.savefig('figs/compare_UNet.png', bbox_inches = 'tight', dpi=200)\n",
    "plt.savefig('figs/compare_UNet.pdf', bbox_inches = 'tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a37ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medpy.metric import dc, hd, assd, jc, asd\n",
    "from utils.fun import reverseVector, drawBinary, reverseVectorOne\n",
    "\n",
    "def evalImageMetrics(blank, output, target_lungs, target_heart):\n",
    "    p1, p2, h, c1, c2 = reverseVector(output)\n",
    "    \n",
    "    ptest = drawBinary(blank.copy(), p1)\n",
    "    ptest = drawBinary(ptest, p2)\n",
    "    \n",
    "    hdp = hd(ptest, target_lungs, voxelspacing = 0.35)\n",
    "    dcp = dc(ptest, target_lungs)\n",
    "\n",
    "    p1, p2, h, c1, c2 = reverseVector(output)\n",
    "    \n",
    "    ptest = drawBinary(blank.copy(), h)\n",
    "    \n",
    "    hdc = hd(ptest, target_heart, voxelspacing = 0.35)\n",
    "    dcc = dc(ptest, target_heart)\n",
    "    \n",
    "    return [dcp, dcc, hdp, hdc]\n",
    "\n",
    "def evalImageMetricsUNet(output, target_lungs, target_heart):\n",
    "    dcp = dc(output == 1, target_lungs)\n",
    "    dcc = dc(output == 2, target_heart)\n",
    "    \n",
    "    hdp = hd(output == 1, target_lungs, voxelspacing = 0.35)\n",
    "    hdc = hd(output == 2, target_heart, voxelspacing = 0.35)\n",
    "        \n",
    "    return [dcp, dcc, hdp, hdc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dfc867-281d-44e3-bd39-88e8764aa974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medpy.metric import dc, hd, assd, jc, asd\n",
    "from utils.fun import reverseVector, drawBinary, reverseVectorOne\n",
    "\n",
    "def evalImageMetrics(blank, output, target_lungs):\n",
    "    p1 = reverseVectorOne(output, 15)\n",
    "    \n",
    "    ptest = drawBinary(blank.copy(), p1)\n",
    "    \n",
    "    hdp = hd(ptest, target_lungs, voxelspacing = 0.35)\n",
    "    dcp = dc(ptest, target_lungs)\n",
    "\n",
    "    return [dcp, hdp]\n",
    "\n",
    "def evalImageMetricsUNet(output, target_lungs):\n",
    "    dcp = dc(output == 1, target_lungs)\n",
    "    #dcc = dc(output == 2, target_heart)\n",
    "    \n",
    "    hdp = hd(output == 1, target_lungs, voxelspacing = 0.35)\n",
    "    #hdc = hd(output == 2, target_heart, voxelspacing = 0.35)\n",
    "        \n",
    "    return [dcp, hdp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dadac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros([1024, 1024])\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(test_dataset.images)):\n",
    "    print('\\r',i+1,'of', len(test_dataset.images),end='')\n",
    "    with torch.no_grad():\n",
    "        sample = test_dataset[i]\n",
    "\n",
    "        data, target = sample['image'], sample['landmarks']\n",
    "        data = torch.unsqueeze(data, 0).to(device)\n",
    "        target =  target.reshape(-1).numpy()\n",
    "        \n",
    "        #p1, p2, h, c1, c2 = reverseVector(target * 1024)\n",
    "        p1 = reverseVectorOne(target * 1024, 15)\n",
    "        \n",
    "        t_lungs = drawBinary(blank.copy(), p1)\n",
    "        #t_lungs = drawBinary(t_lungs, p2)\n",
    "        #t_heart = drawBinary(blank.copy(), h)\n",
    "        \n",
    "        for j in range(0, len(model_list)):\n",
    "            output = model_list[j](data)\n",
    "            if len(output) > 1:\n",
    "                output = output[0]\n",
    "                \n",
    "            output = output.cpu().numpy().reshape(-1) \n",
    "            \n",
    "            metrics = evalImageMetrics(blank, output * 1024, t_lungs)#, t_heart)\n",
    "             \n",
    "            aux = pd.DataFrame([[i, model_names[j]] + metrics], columns=['i','Model','Dice Lungs','HD Lungs'])\n",
    "            results = pd.concat([results, aux], ignore_index=True) #results = results.append(aux, ignore_index = True)\n",
    "        \n",
    "        out = modelUNet(data)[0,:,:,:]\n",
    "        seg = torch.argmax(out, axis = 0).cpu().numpy()\n",
    "        metrics = evalImageMetricsUNet(seg, t_lungs)#, t_heart)\n",
    "        \n",
    "        aux = pd.DataFrame([[i, 'UNet'] + metrics], columns=['i','Model','Dice Lungs','HD Lungs'])\n",
    "        results = pd.concat([results, aux], ignore_index=True) #results = results.append(aux, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a8e15-508e-460b-970f-f701c6ead801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(all_files)):\n",
    "    print('\\r',i+1,'of', len(all_files),end='')\n",
    "    \n",
    "    data = np.load(all_files[i])[:240]\n",
    "    target = np.load(all_files[i].replace(folder, test))[:240]\n",
    "    \n",
    "    p1 = reverseVectorOne(target, 15)\n",
    "       \n",
    "    t_lungs = drawBinary(blank.copy(), p1)\n",
    "    #t_lungs = drawBinary(t_lungs, p2)\n",
    "    #t_heart = drawBinary(blank.copy(), h)\n",
    "        \n",
    "    metrics = evalImageMetrics(blank, data, t_lungs)#, t_heart)\n",
    "        \n",
    "    aux = pd.DataFrame([[i, \"MultiAtlas\"] + metrics], columns=['i','Model','Dice Lungs','HD Lungs'])#['i','Model','Dice Lungs','Dice Heart','HD Lungs','HD Heart'])#, 'ASD Lungs', 'ASD Heart'])\n",
    "    results = pd.concat([results, aux], ignore_index=True) #results = results.append(aux, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149273d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "results['Dice Average'] = results['Dice Lungs'] #[['Dice Lungs', 'Dice Heart']].mean(axis=1)\n",
    "results['HD Average'] = results['HD Lungs'] #['HD Lungs', 'HD Heart']].mean(axis=1)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.tight_layout()\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.boxplot(x = 'Model', y = 'Dice Average', data = results, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('Dice')\n",
    "plt.title('Dice Average')\n",
    "plt.xlabel(None)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "sns.boxplot(x = 'Model', y = 'HD Average', data = results, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('HD (mm)')\n",
    "plt.title('Hausdorff Distance')\n",
    "plt.xlabel(None)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figs/num3.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print('Dice')\n",
    "for model in model_names:\n",
    "    print(model, '%.3f'%np.mean(results['Dice Average'][results['Model'] == model]), '+- %.3f' % np.std(results['Dice Average'][results['Model'] == model]))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Hausdorff')\n",
    "for model in model_names:\n",
    "    print(model, '%.3f'%np.mean(results['HD Average'][results['Model'] == model]), '+- %.3f' % np.std(results['HD Average'][results['Model'] == model]))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaaa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.tight_layout()\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.boxplot(x = 'Model', y = 'Dice Lungs', data = results, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('Dice Lungs')\n",
    "plt.title('Dice Lungs')\n",
    "plt.xlabel(None)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "sns.boxplot(x = 'Model', y = 'HD Lungs', data = results, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('HD (mm)')\n",
    "plt.title('Hausdorff Distance')\n",
    "plt.xlabel(None)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figs/num2.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print('Dice')\n",
    "for model in model_names:\n",
    "    print(model, '%.3f'%np.mean(results['Dice Lungs'][results['Model'] == model]), '+- %.3f' % np.std(results['Dice Lungs'][results['Model'] == model]))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Hausdorff')\n",
    "for model in model_names:\n",
    "    print(model, '%.3f'%np.mean(results['HD Lungs'][results['Model'] == model]), '+- %.3f' % np.std(results['HD Lungs'][results['Model'] == model]))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.tight_layout()\n",
    "ax = plt.subplot(1,2,1)\n",
    "sns.boxplot(x = 'Model', y = 'Dice Heart', data = results, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('Dice Heart')\n",
    "plt.title('Dice Heart')\n",
    "plt.xlabel(None)\n",
    "\n",
    "ax = plt.subplot(1,2,2)\n",
    "sns.boxplot(x = 'Model', y = 'HD Heart', data = results, showmeans = True)\n",
    "plt.xticks(rotation=25, ha=\"right\" )\n",
    "plt.ylabel('HD (mm)')\n",
    "plt.title('Hausdorff Distance')\n",
    "plt.xlabel(None)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figs/num1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print('Dice')\n",
    "for model in model_names:\n",
    "    print(model, '%.3f'%np.mean(results['Dice Heart'][results['Model'] == model]), '+- %.3f' % np.std(results['Dice Heart'][results['Model'] == model]))\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Hausdorff')\n",
    "for model in model_names:\n",
    "    print(model, '%.3f'%np.mean(results['HD Heart'][results['Model'] == model]), '+- %.3f' % np.std(results['HD Heart'][results['Model'] == model]))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de572ae5-6d4f-4713-9266-8592603fad56",
   "metadata": {},
   "source": [
    "# Supplementary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24524d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "model_names = ['PCA', 'VAE', 'MultiAtlas', 'HybridGNet', '1-SC Layer 3', '1-SC Layer 4','1-SC Layer 5','1-SC Layer 6', '2-SC Layers 4-3', '2-SC Layers 5-4', '2-SC Layers 6-5']\n",
    "\n",
    "nmodels = len(model_names)\n",
    "\n",
    "pvalues_mse = np.zeros([nmodels,nmodels])\n",
    "\n",
    "for i in range(0, nmodels):\n",
    "    for j in range(i+1, nmodels):\n",
    "        model1 = model_names[i]\n",
    "        model2 = model_names[j]\n",
    "                \n",
    "        mse1 = results1[results1['Model'] == model1]['MSE']\n",
    "        mse2 = results1[results1['Model'] == model2]['MSE']\n",
    "        \n",
    "        pvalue = wilcoxon(mse1, mse2)\n",
    "        \n",
    "        pvalues_mse[i, j] = pvalue[1]\n",
    "        \n",
    "\n",
    "pvalues_df = pd.DataFrame(pvalues_mse, columns = model_names)\n",
    "pvalues_df.index = model_names\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9), dpi = 100)\n",
    "\n",
    "# mask\n",
    "mask = np.tril(np.ones_like(pvalues_df, dtype=bool))\n",
    "\n",
    "mask = mask[:-1, 1:]\n",
    "pvalues = pvalues_df.iloc[:-1,1:].copy()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(pvalues, mask=mask, annot=True, fmt=\".2e\", cmap='Blues_r',\n",
    "            vmin=0, vmax=0.1, cbar = False)\n",
    "# yticks\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('MSE comparison over Wilcoxon test (p-values)', x = 0.4)\n",
    "\n",
    "plt.savefig('figs/JSRT_MSE_wilcoxon.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371409ca-7bef-4c0e-b6c7-905a031229a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names.append('UNet')\n",
    "\n",
    "nmodels = len(model_names)\n",
    "\n",
    "pvalues_mse = np.zeros([nmodels,nmodels])\n",
    "\n",
    "for i in range(0, nmodels):\n",
    "    for j in range(i+1, nmodels):\n",
    "        model1 = model_names[i]\n",
    "        model2 = model_names[j]\n",
    "                \n",
    "        mse1 = results[results['Model'] == model1]['Dice Lungs']\n",
    "        mse2 = results[results['Model'] == model2]['Dice Lungs']\n",
    "        pvalue = wilcoxon(mse1, mse2)\n",
    "        \n",
    "        pvalues_mse[i, j] = pvalue[1]        \n",
    "\n",
    "pvalues_df = pd.DataFrame(pvalues_mse, columns = model_names)\n",
    "pvalues_df.index = model_names\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9), dpi = 100)\n",
    "\n",
    "# mask\n",
    "mask = np.tril(np.ones_like(pvalues_df, dtype=bool))\n",
    "\n",
    "mask = mask[:-1, 1:]\n",
    "pvalues = pvalues_df.iloc[:-1,1:].copy()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(pvalues, mask=mask, annot=True, fmt=\".2e\", cmap='Blues_r',\n",
    "            vmin=0, vmax=0.1, cbar = False)\n",
    "# yticks\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Dice lungs comparison over Wilcoxon test (p-values)', x = 0.4)\n",
    "\n",
    "plt.savefig('figs/JSRT_dice_wilcoxon_lungs.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9166a-4d5d-4327-b7db-854e2b86238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodels = len(model_names)\n",
    "\n",
    "pvalues_mse = np.zeros([nmodels,nmodels])\n",
    "\n",
    "for i in range(0, nmodels):\n",
    "    for j in range(i+1, nmodels):\n",
    "        model1 = model_names[i]\n",
    "        model2 = model_names[j]\n",
    "                \n",
    "        mse1 = results[results['Model'] == model1]['Dice Heart']\n",
    "        mse2 = results[results['Model'] == model2]['Dice Heart']\n",
    "        pvalue = wilcoxon(mse1, mse2)\n",
    "        \n",
    "        pvalues_mse[i, j] = pvalue[1]        \n",
    "\n",
    "pvalues_df = pd.DataFrame(pvalues_mse, columns = model_names)\n",
    "pvalues_df.index = model_names\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9), dpi = 100)\n",
    "\n",
    "# mask\n",
    "mask = np.tril(np.ones_like(pvalues_df, dtype=bool))\n",
    "\n",
    "mask = mask[:-1, 1:]\n",
    "pvalues = pvalues_df.iloc[:-1,1:].copy()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(pvalues, mask=mask, annot=True, fmt=\".2e\", cmap='Blues_r',\n",
    "            vmin=0, vmax=0.1, cbar = False)\n",
    "# yticks\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Dice heart comparison over Wilcoxon test (p-values)', x = 0.4)\n",
    "\n",
    "plt.savefig('figs/JSRT_dice_wilcoxon_heart.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodels = len(model_names)\n",
    "\n",
    "pvalues_mse = np.zeros([nmodels,nmodels])\n",
    "\n",
    "for i in range(0, nmodels):\n",
    "    for j in range(i+1, nmodels):\n",
    "        model1 = model_names[i]\n",
    "        model2 = model_names[j]\n",
    "                \n",
    "        mse1 = results[results['Model'] == model1]['HD Lungs']\n",
    "        mse2 = results[results['Model'] == model2]['HD Lungs']\n",
    "        pvalue = wilcoxon(mse1, mse2)\n",
    "        \n",
    "        pvalues_mse[i, j] = pvalue[1]        \n",
    "\n",
    "pvalues_df = pd.DataFrame(pvalues_mse, columns = model_names)\n",
    "pvalues_df.index = model_names\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9), dpi = 100)\n",
    "\n",
    "# mask\n",
    "mask = np.tril(np.ones_like(pvalues_df, dtype=bool))\n",
    "\n",
    "mask = mask[:-1, 1:]\n",
    "pvalues = pvalues_df.iloc[:-1,1:].copy()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(pvalues, mask=mask, annot=True, fmt=\".2e\", cmap='Blues_r',\n",
    "            vmin=0, vmax=0.1, cbar = False)\n",
    "# yticks\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('HD lungs comparison over Wilcoxon test (p-values)', x = 0.4)\n",
    "\n",
    "plt.savefig('figs/JSRT_HD_wilcoxon_lungs.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb696a-79cb-4f4e-a9fa-b51ff7a9a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodels = len(model_names)\n",
    "\n",
    "pvalues_mse = np.zeros([nmodels,nmodels])\n",
    "\n",
    "for i in range(0, nmodels):\n",
    "    for j in range(i+1, nmodels):\n",
    "        model1 = model_names[i]\n",
    "        model2 = model_names[j]\n",
    "                \n",
    "        mse1 = results[results['Model'] == model1]['HD Heart']\n",
    "        mse2 = results[results['Model'] == model2]['HD Heart']\n",
    "        pvalue = wilcoxon(mse1, mse2)\n",
    "        \n",
    "        pvalues_mse[i, j] = pvalue[1]        \n",
    "\n",
    "pvalues_df = pd.DataFrame(pvalues_mse, columns = model_names)\n",
    "pvalues_df.index = model_names\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9), dpi = 100)\n",
    "\n",
    "# mask\n",
    "mask = np.tril(np.ones_like(pvalues_df, dtype=bool))\n",
    "\n",
    "mask = mask[:-1, 1:]\n",
    "pvalues = pvalues_df.iloc[:-1,1:].copy()\n",
    "\n",
    "# plot heatmap\n",
    "sns.heatmap(pvalues, mask=mask, annot=True, fmt=\".2e\", cmap='Blues_r',\n",
    "            vmin=0, vmax=0.1, cbar = False)\n",
    "# yticks\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('HD heart comparison over Wilcoxon test (p-values)', x = 0.4)\n",
    "\n",
    "plt.savefig('figs/JSRT_HD_wilcoxon_heart.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e1123-944f-4d7f-98bc-de7cf1649988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
